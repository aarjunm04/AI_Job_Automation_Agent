# ğŸ¤– AI Job Automation Agent

<div align="center">

**A fully autonomous, multi-agent job application ecosystem â€” discover, score, and apply to hundreds of remote jobs with minimal human intervention.**

[![Python](https://img.shields.io/badge/Python-3.11+-blue?style=flat-square&logo=python)](https://www.python.org/)
[![CrewAI](https://img.shields.io/badge/Framework-CrewAI-orange?style=flat-square)](https://crewai.com)
[![License](https://img.shields.io/badge/License-MIT-green?style=flat-square)](LICENSE)
[![Schedule](https://img.shields.io/badge/Schedule-Mon%2FThu%2FSat%2012%3A00%20IST-purple?style=flat-square)]()
[![Budget](https://img.shields.io/badge/Budget-%2410%2Fmonth-red?style=flat-square)]()
[![Status](https://img.shields.io/badge/Status-In%20Development-yellow?style=flat-square)]()

</div>

---

## ğŸ“‹ Table of Contents

- [Overview](#-overview)
- [How It Works](#-how-it-works)
- [Agent System](#-agent-system)
- [Platform Coverage](#-platform-coverage)
- [Tech Stack](#-tech-stack)
- [Scoring & Routing](#-scoring--routing)
- [RAG Resume System](#-rag-resume-system)
- [Infrastructure](#-infrastructure)
- [Setup & Installation](#-setup--installation)
- [Environment Variables](#-environment-variables)
- [Project Roadmap](#-project-roadmap)
- [Repository Structure](#-repository-structure)
- [Budget](#-budget)
- [License](#-license)

---

## ğŸ¯ Overview

The **AI Job Automation Agent** is a fully autonomous agentic job application system engineered to run **3 scheduled batch sessions per week** â€” Monday, Thursday, and Saturday at **12:00 PM IST** â€” and handle the complete end-to-end job application pipeline with minimal human intervention.

| Metric | Target |
|--------|--------|
| Runs per week | 3 â€” Mon / Thu / Sat @ 12:00 PM IST |
| Jobs discovered per run | ~150 (min 100 before safety-net activates) |
| Auto-apply rate | 50â€“70% of eligible jobs per run |
| Manual queue rate | 30â€“50% of eligible jobs per run |
| Monthly applications | ~300+ across ~13 runs |
| Total API budget | **$10/month hard cap** |
| xAI spend cap per run | **$0.38 â€” enforced in code** |

**The system executes two parallel application paths:**

- **Automated Path (50â€“70%)** â€” Playwright browser automation handles form filling and submission end-to-end with zero user action needed.
- **Manual Queue Path (30â€“50%)** â€” High-stakes, high-scoring (>0.90 fit), form-complex, or low-confidence jobs are queued in Notion with full metadata, resume recommendations, and match reasoning, surfaced via Chrome Extension for focused human review.

> âš ï¸ **Critical design rule:** Auto-apply routing is determined by **form complexity + platform compliance ONLY**. Fit score is used for ranking and prioritisation â€” never for routing decisions.

---

## âš™ï¸ How It Works

Every run follows this exact sequence, orchestrated by **CrewAI in hierarchical mode** with the Master Agent as crew manager:

```
GitHub Actions Cron  â†’  0 6 * * 1,4,6  (UTC = 12:00 PM IST)
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Master Agent                  â”‚
â”‚  (CrewAI Crew Manager)                   â”‚
â”‚  Groq llama-3.3-70b-versatile            â”‚
â”‚  â†’ Session boot Â· budget enforcement     â”‚
â”‚  â†’ Delegates sequentially to all workers â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Scraper Agent                 â”‚
â”‚  Perplexity sonar                        â”‚
â”‚  â†’ JobSpy (LinkedIn + Indeed)            â”‚
â”‚  â†’ Playwright (8 platforms)              â”‚
â”‚  â†’ REST APIs (RemoteOK + Himalayas)      â”‚
â”‚  â†’ SerpAPI (Google Jobs supplementary)  â”‚
â”‚  â†’ Normalise Â· deduplicate Â· fill gaps  â”‚
â”‚  WRITES â†’ Postgres jobs table            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Analyser Agent                 â”‚
â”‚  xAI grok-4-fast-reasoning               â”‚
â”‚  â†’ Eligibility filter                    â”‚
â”‚  â†’ Fit scoring (0.0 â€“ 1.0)              â”‚
â”‚  â†’ RAG resume match (ChromaDB)           â”‚
â”‚  â†’ Routing decision (form complexity)    â”‚
â”‚  WRITES â†’ jobs table Â· applications      â”‚
â”‚           table Â· Notion Applications DB â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Apply Agent                   â”‚
â”‚  xAI grok-4-1-fast-reasoning             â”‚
â”‚  â†’ Platform-specific Playwright scripts  â”‚
â”‚  â†’ LLM form reasoning for complex fields â”‚
â”‚  â†’ Multi-layer submission proof capture  â”‚
â”‚  â†’ Retry Ã—2 on CAPTCHA / crash           â”‚
â”‚  WRITES â†’ applications table             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Tracker Agent                  â”‚
â”‚  Groq llama-3.3-70b-versatile            â”‚
â”‚  â†’ Postgres audit logging                â”‚
â”‚  â†’ Notion Job Tracker DB sync            â”‚
â”‚  â†’ AgentOps run summary report           â”‚
â”‚  â†’ run_session marked complete           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

All agent handoffs persist state exclusively to **Postgres tables** â€” making every step fully traceable, restartable from checkpoint, and independently debuggable without re-running the full pipeline.

### Manual Apply Path (Chrome Extension)

Triggered independently by the user outside the automated pipeline:

1. User reviews queued jobs in Notion Applications DB
2. Opens job URL in Chrome â€” Extension detects the application form
3. Extension calls **FastAPI â†’ ChromaDB RAG** â†’ returns best resume + match reasoning + autofill data
4. Extension autofills all detectable fields â€” user handles custom questions manually
5. On submission: Extension calls FastAPI â†’ logs to Postgres `applications` (status: `applied_manual`) â†’ triggers Notion sync

---

## ğŸ¤– Agent System

The system uses **CrewAI** (open-source, free) as the agent orchestration framework. All agents run in a single Python process per session. Every agent capability â€” Postgres reads/writes, Playwright calls, RAG queries, Notion sync â€” is implemented as a `@tool` decorated Python function registered to its agent.

| Agent | Role | Primary LLM | Fallback 1 | Fallback 2 | Phase |
|-------|------|-------------|------------|------------|-------|
| **Master Agent** | Crew Manager â€” Orchestrator | Groq `llama-3.3-70b-versatile` | Cerebras `llama-3.3-70b` | â€” | 1 + 2 |
| **Scraper Agent** | Job Discovery Specialist | Perplexity `sonar` | *(no fallback â€” web search irreplaceable)* | â€” | 1 + 2 |
| **Analyser Agent** | Evaluation & Scoring Specialist | xAI `grok-4-fast-reasoning` | SambaNova `Llama-3.1-70B` | Cerebras `llama-3.3-70b` | 1 + 2 |
| **Apply Agent** | Application Submission Specialist | xAI `grok-4-1-fast-reasoning` | SambaNova `Llama-3.1-70B` | Cerebras `llama-3.3-70b` | 1 + 2 |
| **Tracker Agent** | Record Keeper & Data Persistence | Groq `llama-3.3-70b-versatile` | Cerebras `llama-3.3-70b` | â€” | 1 + 2 |
| **Developer Agent** | System Improvement Analyst | xAI `grok-3-mini-latest` | Perplexity `sonar` | â€” | **Phase 2 only** |

**Fallback behaviour:**
- **Master / Tracker:** 1-level fallback (Cerebras). Failure in these agents degrades logging â€” does not kill the run.
- **Analyser / Apply:** 2-level fallback chain (SambaNova â†’ Cerebras). These agents are run-critical; chain exhaustion routes remaining jobs to manual queue and continues.
- **Scraper:** No fallback. Perplexity `sonar`'s web-grounded search + normalisation cannot be replicated by a pure inference LLM. Retries Ã—3, then continues with raw platform data.
- **Developer Agent (Phase 2):** Runs outside the main pipeline. Analyses AgentOps traces across sessions and writes structured improvement suggestions to `developer_notes` Postgres table. Suggestion-only â€” never autonomously modifies production.

---

## ğŸŒ Platform Coverage

### Primary Platforms (10) â€” Phase 1 + 2

| Platform | Discovery Method | Category |
|----------|-----------------|----------|
| LinkedIn | JobSpy | Professional Network |
| Indeed | JobSpy | General Job Board |
| Wellfound | Playwright + GraphQL | Startup Jobs |
| RemoteOK | REST API (JSON) | Remote Job Board |
| WeWorkRemotely | Playwright | Remote-First Jobs |
| YC / Work at a Startup | Playwright | YC Startup Jobs |
| Himalayas | REST API (public) | Remote Aggregator |
| Turing | Playwright | Premium Talent |
| Crossover | Playwright | Premium Remote |
| Arc.dev | Playwright + GraphQL | Developer Marketplace |

### Safety-Net Platforms (2) â€” auto-activate when run < 100 jobs

| Platform | Discovery Method |
|----------|-----------------|
| Nodesk | Playwright |
| Toptal | Playwright |

### Phase 2 Platforms (2)

| Platform | Discovery Method |
|----------|-----------------|
| Remotive | REST API |
| Jooble | REST API (API key required) |

### Supplementary Discovery

**SerpAPI** â€” Google Jobs search results API (NOT an LLM).
4 accounts Ã— 250 credits = **1,000 credits/month** available.

### Proxy Configuration

**Webshare static proxies** â€” 20 total (2 accounts Ã— 10 proxies), 1 GB bandwidth/account/month, round-robin rotation. Budget is separate from the $10/month LLM cap.

---

## ğŸ› ï¸ Tech Stack

| Layer | Technology | Purpose | Tier |
|-------|-----------|---------|------|
| Language | Python 3.11+ | All agents Â· orchestration Â· services | Free |
| Agent Framework | CrewAI (OSS) | Agent roles Â· task definitions Â· hierarchical crew execution Â· `@tool` functions | Free |
| Job Scraping | JobSpy | LinkedIn + Indeed structured discovery | Free |
| Browser Automation | Playwright (Chromium) | 8-platform scraping + form filling + auto-apply | Free |
| Job APIs | requests | RemoteOK + Himalayas REST calls | Free |
| Supplementary Discovery | SerpAPI | Google Jobs search results (4 accounts Â· 1K credits/month) | Free tier |
| Primary DB (Prod) | PostgreSQL via Supabase | System of record â€” jobs Â· applications Â· run_sessions Â· audit_logs | Free tier |
| Primary DB (Dev) | PostgreSQL (local Docker) | Dev mirror â€” switched via `ACTIVE_DB` env var | Free |
| Vector Store | ChromaDB (local) | Resume + job embeddings for RAG matching | Free |
| Primary Embeddings | NVIDIA NIM `nv-embedqa-e5-v5` | 1024-dim embeddings | Free tier |
| Fallback Embeddings | Gemini `text-embedding-004` | 768-dim fallback if NVIDIA NIM unavailable | Free tier |
| Cache / Queue | Redis (local Docker) | Phase 1: response caching Â· Phase 2: full job queue | Free |
| User Tracking UI | Notion API v1 | Applications DB + Job Tracker DB (UI only â€” not source of truth) | Free tier |
| API Layer | FastAPI (slim) | Chrome Extension HTTP bridge Â· RAG proxy Â· manual apply logging | Free |
| Manual Assist | Chrome Extension v1 | Autofill Â· match analysis Â· resume suggestion Â· tracking | Free |
| Containerisation | Docker + Docker Compose | Full local dev stack | Free |
| CI/CD + Cron Scheduler | GitHub Actions | `0 6 * * 1,4,6` UTC Â· CI/CD pipelines | Free tier |
| Observability | AgentOps | Agent traces Â· LLM cost tracking Â· error patterns | Free tier |
| Secrets Management | `~/java.env` | Single git-ignored env file â€” passed to Docker via `--env-file` | Free |

### LLM Provider Summary

| Provider | Models Used | Tier | Monthly Budget |
|----------|------------|------|----------------|
| **xAI** | `grok-4-fast-reasoning` (Analyser) Â· `grok-4-1-fast-reasoning` (Apply) Â· `grok-3-mini-latest` (Dev Agent P2) | Paid | **$5/month** |
| **Perplexity** | `sonar` (Scraper) Â· `sonar` fallback (Dev Agent P2) | Paid | **$5/month** |
| **Groq** | `llama-3.3-70b-versatile` (Master + Tracker) | Free tier | â€” |
| **Cerebras** | `llama-3.3-70b` (All agent fallbacks) | Free tier | â€” |
| **SambaNova** | `Llama-3.1-70B` (Analyser + Apply fallback 1) | Free tier | â€” |
| **NVIDIA NIM** | `nv-embedqa-e5-v5` (Primary embeddings) | Free tier | â€” |
| **Google Gemini** | `text-embedding-004` (Fallback embeddings) | Free tier | â€” |

> **Hard cap: $10/month total LLM spend Â· $0.38/run xAI cap â€” both enforced in code. Run aborts gracefully if cap is hit.**

---

## ğŸ“Š Scoring & Routing

Every eligible job is scored on a **0.0 â€“ 1.0 fit scale** by the Analyser Agent using skills match, experience alignment, role relevance, and seniority fit. Routing is a separate decision based solely on form complexity and platform compliance.

| Fit Score | Action |
|-----------|--------|
| `< 0.40` | âŒ Skip entirely â€” no Notion entry Â· no Postgres record |
| `0.40 â€“ 0.49` | ğŸ“‹ Manual queue only â€” low confidence, never auto-applied |
| `0.50 â€“ 0.74` | âš–ï¸ Route by form complexity â€” auto-apply or manual |
| `â‰¥ 0.75` | âœ… Route by form complexity â€” auto-apply or manual |
| `> 0.90` | ğŸ“‹ **Force manual queue** â€” high match = high stakes, always manual |

> **Routing rule: Form complexity + platform compliance ONLY. Fit score is used for ranking and prioritisation â€” never for auto-apply routing decisions.**

---

## ğŸ§  RAG Resume System

The RAG system matches every scored job to the optimal resume variant using a local ChromaDB vector search against all 15 resume embeddings.

| Config | Detail |
|--------|--------|
| Vector Store | ChromaDB (fully local, persistent on disk) |
| Primary Embeddings | NVIDIA NIM `nv-embedqa-e5-v5` â€” 1024 dimensions |
| Fallback Embeddings | Gemini `text-embedding-004` â€” 768 dimensions |
| Total Resume Variants | **15** |
| RAG Failure Fallback | `Aarjun_Gen.pdf` assigned as default if ChromaDB query fails |

### Resume Variants

| # | File | Type |
|---|------|------|
| 1 | `Aarjun_Gen.pdf` | General |
| 2 | `Aarjun_OG.pdf` | Original / Base |
| 3 | `Aarjun_AIAutomation.pdf` | Domain-specific |
| 4 | `Aarjun_AIML.pdf` | Domain-specific |
| 5 | `Aarjun_AISolutionsArchitect.pdf` | Domain-specific |
| 6 | `Aarjun_AppliedML.pdf` | Domain-specific |
| 7 | `Aarjun_DataEngineering.pdf` | Domain-specific |
| 8 | `Aarjun_DataScience.pdf` | Domain-specific |
| 9 | `Aarjun_FeatureEngineering.pdf` | Domain-specific |
| 10 | `Aarjun_LLMFineTuning.pdf` | Domain-specific |
| 11 | `Aarjun_LLMGenAI.pdf` | Domain-specific |
| 12 | `Aarjun_MLDataEngineer.pdf` | Domain-specific |
| 13 | `Aarjun_MLOps.pdf` | Domain-specific |
| 14 | `Aarjun_PromptEngineer.pdf` | Domain-specific |
| 15 | `Aarjun_RAGEngineer.pdf` | Domain-specific |

---

## âš™ï¸ Infrastructure

### Data Layer

| Store | Technology | Role |
|-------|-----------|------|
| System of Record | PostgreSQL â€” Supabase (prod) / local Docker (dev) | `jobs` Â· `applications` Â· `run_sessions` Â· `audit_logs` |
| Vector Store | ChromaDB (local) | Resume + job embeddings â€” RAG only |
| Cache / Queue | Redis (local Docker) | Phase 1: response caching Â· Phase 2: full queue + inter-service cache |
| User UI | Notion API v1 | Applications DB Â· Job Tracker DB â€” read/write UI surface only |

Switch between prod and dev database via `ACTIVE_DB` environment variable (`supabase` or `local`).

### Notion Databases

**Applications DB** â€” manual queue jobs awaiting user review:
`Job Title` Â· `Company` Â· `Job URL` Â· `Application Deadline` Â· `Platform` Â· `Status` Â· `Fit Score` Â· `Resume Suggested` Â· `Match Reasoning` Â· `CTC` Â· `Priority` Â· `Run ID`

**Job Tracker DB** â€” applied jobs pipeline:
`Job Title` Â· `Company` Â· `Job URL` Â· `Stage` Â· `Date Applied` Â· `Platform` Â· `Applied Via` Â· `CTC` Â· `Notes` Â· `Run ID`

### Cron Schedule

```
GitHub Actions Cron:  0 6 * * 1,4,6
Timezone:             UTC â†’ 12:00 PM IST
Days:                 Monday (1) Â· Thursday (4) Â· Saturday (6)
Approx runs/month:    ~13
```

### Secrets Management

All secrets live in `~/java.env` â€” a single, **git-ignored** file that is the source of truth for all API keys, DB URLs, and config values. Auto-loaded by the shell and passed to all Docker containers via `--env-file ~/java.env`.

---

## ğŸ”§ Setup & Installation

### Prerequisites

- Python 3.11+
- Docker + Docker Compose
- Git
- Chrome / Chromium (for extension)

### Step 1 â€” Clone Repository

```bash
git clone https://github.com/aarjunm04/AI_Job_Automation_Agent.git
cd AI_Job_Automation_Agent
```

### Step 2 â€” Configure Environment

```bash
# Create the global env file (single source of truth â€” git-ignored)
touch ~/java.env
nano ~/java.env   # Add all required variables â€” see Environment Variables section below
```

### Step 3 â€” Boot Full Stack

```bash
# Start all services: Postgres, Redis, FastAPI
docker-compose --env-file ~/java.env up -d

# Verify all containers are healthy
docker-compose ps
```

### Step 4 â€” Install Python Dependencies

```bash
python -m venv venv
source venv/bin/activate   # Windows: venv\Scripts\activate
pip install -r requirements.txt
playwright install chromium
```

### Step 5 â€” Initialise Database & RAG

```bash
# Run Postgres schema migrations
python scripts/migrate_db.py

# Embed all 15 resume variants into local ChromaDB
python scripts/embed_resumes.py
```

### Step 6 â€” Verify Setup

```bash
python main.py --health-check
# Expected: âœ… All systems healthy
```

---

## ğŸ” Environment Variables

All variables live in `~/java.env`. This file is never committed to git and is auto-loaded by your shell and Docker via `--env-file`.

```env
# â”€â”€ LLM APIs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
XAI_API_KEY=                        # xAI â€” Analyser + Apply agents + Dev Agent (Phase 2)
PERPLEXITY_API_KEY=                  # Perplexity â€” Scraper sonar + Dev Agent fallback (P2)
GROQ_API_KEY=                        # Groq â€” Master + Tracker agents
CEREBRAS_API_KEY=                    # Cerebras â€” all agent fallbacks
SAMBANOVA_API_KEY=                   # SambaNova â€” Analyser + Apply fallback 1
NVIDIA_NIM_API_KEY=                  # NVIDIA NIM â€” primary embeddings (nv-embedqa-e5-v5)
GEMINI_API_KEY=                      # Google Gemini â€” fallback embeddings (text-embedding-004)

# â”€â”€ Database â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ACTIVE_DB=supabase                   # supabase | local  (switches DB target)
SUPABASE_URL=                        # Supabase project URL
SUPABASE_KEY=                        # Supabase service/anon key
LOCAL_POSTGRES_URL=                  # postgresql://user:pass@localhost:5432/dbname

# â”€â”€ Notion â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
NOTION_API_KEY=                      # Notion integration token
NOTION_APPLICATIONS_DB_ID=           # Applications DB â€” manual queue
NOTION_JOB_TRACKER_DB_ID=            # Job Tracker DB â€” applied pipeline

# â”€â”€ Discovery â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SERPAPI_KEY_1=                       # SerpAPI account 1 (250 credits/month)
SERPAPI_KEY_2=                       # SerpAPI account 2 (250 credits/month)
SERPAPI_KEY_3=                       # SerpAPI account 3 (250 credits/month)
SERPAPI_KEY_4=                       # SerpAPI account 4 (250 credits/month)
JOOBLE_API_KEY=                      # Jooble REST API key (Phase 2 only)

# â”€â”€ Proxies â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
WEBSHARE_PROXY_LIST=                 # Comma-separated list of 20 static proxy addresses

# â”€â”€ Platform Credentials â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
LINKEDIN_EMAIL=
LINKEDIN_PASSWORD=

# â”€â”€ Observability â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
AGENTOPS_API_KEY=                    # AgentOps â€” traces + cost tracking

# â”€â”€ Budget Enforcement â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
XAI_BUDGET_CAP_PER_RUN=0.38          # Hard xAI spend cap per run (USD)
XAI_MONTHLY_BUDGET=5.00              # xAI monthly budget (USD)
PERPLEXITY_MONTHLY_BUDGET=5.00       # Perplexity monthly budget (USD)

# â”€â”€ System â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TIMEZONE=Asia/Kolkata
```

---

## ğŸ—ºï¸ Project Roadmap

### Phase 1 â€” Core System Build (4 Weeks)

| Milestone | Target | Deliverable |
|-----------|--------|-------------|
| **M1** | Week 1 | Repo structure Â· Docker Compose Â· `java.env` schema Â· Postgres schema + Supabase setup Â· ChromaDB init |
| **M2** | Week 1â€“2 | RAG system live â€” all 15 resumes embedded Â· NVIDIA NIM primary + Gemini fallback |
| **M3** | Week 2 | CrewAI framework setup Â· Master Agent Â· AgentOps integration |
| **M4** | Week 2â€“3 | Scraper Agent â€” all 10 platforms + safety-net Â· SerpAPI Â· Perplexity `sonar` normalisation |
| **M5** | Week 3 | Analyser Agent â€” eligibility filter Â· fit scoring Â· RAG match Â· routing decision |
| **M6** | Week 3â€“4 | Apply Agent â€” all platform Playwright scripts Â· retry logic Â· submission proof capture |
| **M7** | Week 4 | Tracker Agent Â· Notion sync Â· FastAPI slim server Â· Chrome Extension v1 |
| **ğŸš€ M8** | **End of Week 4** | **Phase 1 Launch â€” first live fully autonomous run** |

### Phase 2 â€” Self-Improving System (8 Weeks)

| Milestone | Target | Deliverable |
|-----------|--------|-------------|
| **M9** | Week 5â€“6 | Redis full queue + inter-service cache system |
| **M10** | Week 6â€“7 | Developer Agent live â€” `grok-3-mini-latest` Â· AgentOps cross-session trace analysis |
| **M11** | Week 7â€“8 | Remotive + Jooble platform integration Â· all-round resume variant |
| **ğŸ M12** | **End of Week 8** | **Phase 2 Complete â€” self-improving autonomous system** |

---

## ğŸ“ Repository Structure

```
AI_Job_Automation_Agent/
â”‚
â”œâ”€â”€ main.py                         # Entry point â€” run session trigger
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ docker-compose.yml              # Full local dev stack (Postgres Â· Redis Â· FastAPI)
â”‚
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ run_agent.yml           # GitHub Actions cron: 0 6 * * 1,4,6 (UTC = 12PM IST)
â”‚
â”œâ”€â”€ agents/                         # CrewAI Agent + Task definitions
â”‚   â”œâ”€â”€ master_agent.py             # Crew Manager â€” session boot Â· budget enforcement Â· orchestration
â”‚   â”œâ”€â”€ scraper_agent.py            # Discovery specialist â€” all platforms + normalisation
â”‚   â”œâ”€â”€ analyser_agent.py           # Scoring + routing specialist â€” RAG match Â· fit scoring
â”‚   â”œâ”€â”€ apply_agent.py              # Submission specialist â€” Playwright form filling
â”‚   â”œâ”€â”€ tracker_agent.py            # Record keeper â€” Postgres Â· Notion Â· AgentOps
â”‚   â””â”€â”€ developer_agent.py          # Phase 2 â€” improvement analyst (runs outside pipeline)
â”‚
â”œâ”€â”€ tools/                          # @tool decorated functions registered to CrewAI agents
â”‚   â”œâ”€â”€ postgres_tools.py           # DB read/write tools
â”‚   â”œâ”€â”€ playwright_tools.py         # Browser automation tools
â”‚   â”œâ”€â”€ rag_tools.py                # ChromaDB vector search + resume selection tools
â”‚   â”œâ”€â”€ notion_tools.py             # Notion API read/write tools
â”‚   â”œâ”€â”€ scraper_tools.py            # JobSpy Â· REST API Â· SerpAPI tools
â”‚   â””â”€â”€ agentops_tools.py           # Observability + cost tracking tools
â”‚
â”œâ”€â”€ scrapers/                       # Platform scraper implementations
â”‚   â”œâ”€â”€ jobspy_scraper.py           # LinkedIn + Indeed via JobSpy library
â”‚   â”œâ”€â”€ remoteok_api.py             # RemoteOK public JSON API
â”‚   â”œâ”€â”€ himalayas_api.py            # Himalayas public REST API
â”‚   â””â”€â”€ playwright_scrapers/        # Per-platform Playwright scraper scripts
â”‚       â”œâ”€â”€ wellfound.py
â”‚       â”œâ”€â”€ weworkremotely.py
â”‚       â”œâ”€â”€ yc_startup.py
â”‚       â”œâ”€â”€ turing.py
â”‚       â”œâ”€â”€ crossover.py
â”‚       â”œâ”€â”€ arc_dev.py
â”‚       â”œâ”€â”€ nodesk.py               # Safety-net platform
â”‚       â””â”€â”€ toptal.py               # Safety-net platform
â”‚
â”œâ”€â”€ rag/                            # RAG system
â”‚   â”œâ”€â”€ embedder.py                 # NVIDIA NIM + Gemini fallback embedding logic
â”‚   â”œâ”€â”€ chromadb_store.py           # ChromaDB vector store management
â”‚   â””â”€â”€ resume_matcher.py           # Job-to-resume cosine matching + selection
â”‚
â”œâ”€â”€ db/                             # Database layer
â”‚   â”œâ”€â”€ schema.sql                  # Postgres table definitions (jobs Â· applications Â· run_sessions Â· audit_logs)
â”‚   â”œâ”€â”€ supabase_client.py          # Supabase connection + query interface
â”‚   â””â”€â”€ local_postgres_client.py   # Local Postgres connection (dev)
â”‚
â”œâ”€â”€ api/                            # Slim FastAPI server
â”‚   â””â”€â”€ server.py                   # 3 endpoints: /extension Â· /rag-proxy Â· /manual-log
â”‚
â”œâ”€â”€ chrome_extension/               # Chrome Extension v1
â”‚   â”œâ”€â”€ manifest.json
â”‚   â”œâ”€â”€ popup.html
â”‚   â”œâ”€â”€ popup.js
â”‚   â””â”€â”€ content.js
â”‚
â”œâ”€â”€ config/                         # Static configuration files
â”‚   â”œâ”€â”€ platforms.json              # Per-platform scraping config (rate limits Â· selectors Â· compliance)
â”‚   â””â”€â”€ search_params.json          # Job search parameters (titles Â· keywords Â· filters)
â”‚
â”œâ”€â”€ scripts/                        # Utility scripts
â”‚   â”œâ”€â”€ migrate_db.py               # Run Postgres schema migrations
â”‚   â”œâ”€â”€ embed_resumes.py            # Embed all 15 resume variants into ChromaDB
â”‚   â””â”€â”€ health_check.py             # System-wide health verification
â”‚
â””â”€â”€ resumes/                        # Resume variants â€” git-ignored
    â”œâ”€â”€ Aarjun_Gen.pdf              # General
    â”œâ”€â”€ Aarjun_OG.pdf               # Original / Base
    â”œâ”€â”€ Aarjun_AIAutomation.pdf
    â”œâ”€â”€ Aarjun_AIML.pdf
    â”œâ”€â”€ Aarjun_AISolutionsArchitect.pdf
    â”œâ”€â”€ Aarjun_AppliedML.pdf
    â”œâ”€â”€ Aarjun_DataEngineering.pdf
    â”œâ”€â”€ Aarjun_DataScience.pdf
    â”œâ”€â”€ Aarjun_FeatureEngineering.pdf
    â”œâ”€â”€ Aarjun_LLMFineTuning.pdf
    â”œâ”€â”€ Aarjun_LLMGenAI.pdf
    â”œâ”€â”€ Aarjun_MLDataEngineer.pdf
    â”œâ”€â”€ Aarjun_MLOps.pdf
    â”œâ”€â”€ Aarjun_PromptEngineer.pdf
    â””â”€â”€ Aarjun_RAGEngineer.pdf
```

---

## ğŸ’° Budget

| Service | Monthly Cost | Coverage |
|---------|-------------|----------|
| xAI | **$5.00** | `grok-4-fast-reasoning` (Analyser) Â· `grok-4-1-fast-reasoning` (Apply) Â· `grok-3-mini-latest` (Dev Agent Phase 2) |
| Perplexity | **$5.00** | `sonar` (Scraper) Â· `sonar` Dev Agent fallback (Phase 2) |
| Groq | Free tier | `llama-3.3-70b-versatile` â€” Master + Tracker agents |
| Cerebras | Free tier | `llama-3.3-70b` â€” all agent fallbacks |
| SambaNova | Free tier | `Llama-3.1-70B` â€” Analyser + Apply fallback 1 |
| NVIDIA NIM | Free tier | `nv-embedqa-e5-v5` â€” primary embeddings |
| Google Gemini | Free tier | `text-embedding-004` â€” fallback embeddings |
| Supabase | Free tier | 500 MB DB / 2 GB bandwidth |
| GitHub Actions | Free tier | ~13 runs/month â€” well within 2,000 min/month free limit |
| AgentOps | Free tier | Observability + cost tracking |
| Webshare Proxies | Separate budget | 20 static proxies â€” NOT included in $10 LLM cap |

> **Total LLM hard cap: $10/month Â· Per-run xAI cap: $0.38 â€” both enforced in application code.**

---

## ğŸ“„ License

This project is licensed under the [MIT License](LICENSE).

---

<div align="center">

Built by **Aarjun Mahule**

[â¬† Back to Top](#-ai-job-automation-agent)

</div>
