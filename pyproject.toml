# ============================================================
# pyproject.toml — Narad Job Automation AI Agent
# Python 3.11 | Production-Ready | Zero-Conflict Pinning
# Last Updated: 2026-02-28
# ============================================================

[build-system]
requires      = ["hatchling"]
build-backend = "hatchling.build"

# ── Project Metadata ─────────────────────────────────────────────────────────
[project]
name        = "narad-job-agent"
version     = "0.1.0"
description = "Autonomous AI job application pipeline — scrape, score, apply"
readme      = "README.md"
license     = { text = "MIT" }
requires-python = ">=3.11,<3.12"

# ── Runtime Dependencies ──────────────────────────────────────────────────────
# CONFLICT NOTES:
#   • openai>=1.78 and groq share httpx>=0.23 — resolved by httpx>=0.28.1
#   • pydantic v2 required by fastapi, jobspy, agentops, supabase — unified >=2.11.4
#   • numpy is intentionally OMITTED here; python-jobspy pins numpy==1.26.3
#     internally — adding it here risks conflict. numpy comes as transitive dep.
#   • playwright is pulled transitively by python-jobspy BUT we pin explicitly
#     so the Apply Agent gets the same version as the Scraper Agent.
#   • apscheduler is pinned <4.0 — v4 is still alpha with breaking API changes
#   • agentops 0.4.x uses new decorator API: from agentops.sdk.decorators import agent, operation
#     (replaces old @agentops.track_agent / @agentops.track_tool from v0.3.x)
#   • google-genai is the new consolidated Gemini SDK (replaces google-generativeai)
dependencies = [
    # ── Web Framework ─────────────────────────────────────────────────────────
    "fastapi>=0.115.12,<0.116",          # slim server — exactly 3 endpoints
    "uvicorn[standard]>=0.34.2,<0.35",   # httptools + uvloop bundled via [standard]
    "python-multipart>=0.0.20",          # form/file upload support

    # ── Config & Secrets ──────────────────────────────────────────────────────
    "pydantic>=2.11.4,<3.0",             # shared v2 baseline — no v1 backcompat
    "pydantic-settings>=2.9.1,<3.0",     # reads ~/narad.env via BaseSettings
    "python-dotenv>=1.1.0,<2.0",         # fallback .env loader

    # ── Database ──────────────────────────────────────────────────────────────
    "sqlalchemy[asyncio]>=2.0.40,<3.0",  # ORM + async engine
    "asyncpg>=0.30.0,<1.0",              # async PostgreSQL driver
    "alembic>=1.15.2,<2.0",              # schema migrations
    "supabase>=2.15.0,<3.0",             # Supabase client (free tier)

    # ── Cache ─────────────────────────────────────────────────────────────────
    "redis[hiredis]>=6.0.0,<7.0",        # hiredis C-parser for 10x throughput

    # ── Job Scraping ──────────────────────────────────────────────────────────
    # Transitive deps pulled by python-jobspy:
    #   requests^2.31, beautifulsoup4^4.12, pandas^2.1, numpy==1.26.3,
    #   pydantic^2.3, tls-client^1.0, markdownify^0.13, regex^2024.4
    "python-jobspy>=1.1.82",             # LinkedIn, Indeed, Glassdoor, ZipRecruiter, Bayt, Naukri

    # ── Browser Automation (Apply Agent) ──────────────────────────────────────
    # NOTE: run `playwright install chromium` after pip install
    "playwright>=1.50.0,<2.0",           # Playwright for auto-apply flows

    # ── LLM Providers ─────────────────────────────────────────────────────────
    # openai SDK handles: xAI Grok (XAI_BASE_URL), Perplexity (PPLX_BASE_URL),
    # SambaNova (SAMBA_BASE_URL), NVIDIA NIM (NIM_BASE_URL) — all OpenAI-compatible
    "openai>=1.78.0,<2.0",
    "groq>=0.22.0,<1.0",                 # free tier — primary LLM for scraper
    "google-genai>=1.0.0,<2.0",          # new consolidated Gemini SDK (replaces google-generativeai)

    # ── RAG & Vector Store ────────────────────────────────────────────────────
    # Uses Qdrant free cloud tier. Embeddings via openai SDK to stay within budget.
    "qdrant-client>=1.14.0,<2.0",        # vector DB client (HTTP mode, no grpc needed)
    "tiktoken>=0.9.0,<1.0",              # token counting for embedding chunking

    # ── Agent Observability ───────────────────────────────────────────────────
    # v0.4.x decorator API: from agentops.sdk.decorators import agent, operation
    # Replaces old v0.3.x: @agentops.track_agent / @agentops.track_tool
    "agentops>=0.4.0,<1.0",
    "crewai>=0.95.0,<1.0",               # CrewAI agent framework for tool decorators

    # ── Scheduling ────────────────────────────────────────────────────────────
    # 3 sessions/week cron — v4 is alpha, stay on stable v3
    "apscheduler>=3.10.4,<4.0",

    # ── Integrations ──────────────────────────────────────────────────────────
    "notion-client>=2.3.0,<3.0",         # manual-review queue → Notion pages

    # ── HTTP & Resilience ─────────────────────────────────────────────────────
    # httpx >=0.28.1 satisfies: openai, groq, supabase, fastapi test client
    "httpx>=0.28.1,<1.0",
    "tenacity>=9.0.0,<10.0",             # retry logic: max 3 retries, exp backoff

    # ── Data Processing ───────────────────────────────────────────────────────
    # pandas>=2.2.3 satisfies python-jobspy's ^2.1.0 requirement
    "pandas>=2.2.3,<3.0",

    # ── Security & Auth ───────────────────────────────────────────────────────
    "pyjwt>=2.10.1,<3.0",                # API endpoint JWT validation
    "cryptography>=44.0.0,<46.0",        # JWT signing + key management
    "bcrypt>=4.3.0,<5.0",                # password hashing

    # ── Utilities ─────────────────────────────────────────────────────────────
    "orjson>=3.10.0,<4.0",               # fast JSON serialisation (2-3x stdlib)
    "psutil>=7.0.0,<8.0",                # system resource monitoring
    "python-dateutil>=2.9.0,<3.0",       # robust date parsing for job listings
    "aiofiles>=24.1.0,<25.0",            # async file I/O for resume variants
    "certifi>=2024.12.14",               # up-to-date CA bundle for HTTPS
]

# ── Optional Extras ───────────────────────────────────────────────────────────
[project.optional-dependencies]

# Heavy local embedding model — only install if you have >=8 GB RAM
# Excluded from default install to stay resource-light on free CI/CD runners
rag-local = [
    "sentence-transformers>=3.4.0,<4.0", # local SBERT models
    "torch>=2.3.0,<3.0",                 # CPU-only; install torch+cpu wheel manually
]

dev = [
    # Testing
    "pytest>=8.3.5",
    "pytest-asyncio>=0.25.0",            # asyncio_mode = "auto" set below
    "pytest-cov>=6.1.1",
    "respx>=0.22.0",                     # mock httpx for unit tests

    # Linting & Formatting
    "ruff>=0.11.0",                      # replaces black + isort + flake8

    # Type Checking
    "mypy>=1.15.0",
    "types-redis>=4.6.0",
    "types-python-dateutil>=2.9.0",
    "types-beautifulsoup4>=4.12.0",
    "types-requests>=2.31.0",
    "types-psutil>=7.0.0",
    "types-aiofiles>=24.1.0",

    # Dev Utilities
    "ipython>=9.0.0",
    "rich>=14.0.0",                      # pretty CLI output during dev
]

# ── Entry Points ──────────────────────────────────────────────────────────────
[project.scripts]
narad-agent  = "app.main:start"          # starts FastAPI server via uvicorn
narad-worker = "app.scheduler:start"     # starts APScheduler process

# ── Hatchling Build Config ────────────────────────────────────────────────────
[tool.hatch.build.targets.wheel]
packages = ["app"]

# ── Ruff Linter ───────────────────────────────────────────────────────────────
[tool.ruff]
target-version = "py311"
line-length    = 100
exclude        = ["alembic", ".venv", "__pycache__", "*.pyi"]

[tool.ruff.lint]
select = [
    "E",      # pycodestyle errors
    "W",      # pycodestyle warnings
    "F",      # pyflakes
    "I",      # isort
    "B",      # flake8-bugbear
    "C4",     # flake8-comprehensions
    "UP",     # pyupgrade
    "ASYNC",  # flake8-async (important for FastAPI + asyncpg)
    "SIM",    # flake8-simplify
]
ignore = [
    "E501",   # line too long — handled by line-length above
    "B008",   # do not perform function calls in argument defaults (FastAPI uses this)
    "B904",   # allow raise without from inside except (FastAPI HTTPExceptions)
    "UP007",  # allow Optional[X] syntax (mypy strict prefers X | None but this is cleaner)
]

# ── Mypy Type Checker ─────────────────────────────────────────────────────────
[tool.mypy]
python_version         = "3.11"
strict                 = true
exclude                = ["alembic", "tests", ".venv"]
ignore_missing_imports = true           # suppress missing stubs for third-party libs
disallow_untyped_defs  = true
disallow_any_generics  = true
warn_return_any        = true
warn_unused_ignores    = true
plugins                = ["pydantic.mypy"]

[tool.pydantic-mypy]
init_forbid_extra         = true
init_typed                = true
warn_required_dynamic_aliases = true

# ── Pytest ────────────────────────────────────────────────────────────────────
[tool.pytest.ini_options]
minversion    = "8.0"
asyncio_mode  = "auto"                  # no need for @pytest.mark.asyncio on every test
testpaths     = ["tests"]
addopts       = "--cov=app --cov-report=term-missing --cov-report=xml -v"

# ── Coverage ──────────────────────────────────────────────────────────────────
[tool.coverage.run]
source        = ["app"]
branch        = true
omit          = ["*/__init__.py", "*/alembic/*"]

[tool.coverage.report]
show_missing  = true
skip_covered  = false
fail_under    = 70
exclude_lines = [
    "pragma: no cover",
    "if __name__ == .__main__.:",
    "raise NotImplementedError",
]